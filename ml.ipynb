{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "#this will prepare training data for model\n",
    "\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import array_ops, math_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the data\n",
    "class dataloader(object):\n",
    "    def _init__(self,image_dir,hr_image_size):\n",
    "        self.image_paths = [os.path.jain(image_dir,x)for x in os.listdir(image_dir)]\n",
    "        self.image_size=hr_image_size\n",
    "#parse helps converting image to the machine understanding form\n",
    "    def _parse_image(self,image_path):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.io.decode_jepg(image,channels=3)\n",
    "        image = tf.image.conver_image_dtype(image,tf.float32)\n",
    "        \n",
    "        if tf.kerasbackend.image_data_format() == 'channels_last':\n",
    "            shape= array_ops.shape(image)[:2]\n",
    "        else:\n",
    "            shape = array_ops_shape(image)[1:]\n",
    "        cond = math_ops.reduce_all(shape >= tf.constant(self,image_size))\n",
    "        \n",
    "        image = tf.cond(cond,lambda: tf.identity(image)),lambda: tf.image.resize(image,[self.image_size,self.image_size])\n",
    "        \n",
    "        return image\n",
    "    #random crop helps to randomly crop the image and helps in increase in accuracy in conversion\n",
    "    def _random_crop(self,image):\n",
    "        \n",
    "        low_res =tf.image.randon_crop(image,[self.image_size,self.image_size,3])\n",
    "        return image\n",
    "    def _high_low_res_pairs(self , high_res):\n",
    "        \n",
    "        low_res=tf.image.resize(high_res, [self.image_size//4,self.image_size//4],method='bicubic')\n",
    "        return low_res,high_res\n",
    "    #rescale helps to zoom and unzoom the image for finding accuracy\n",
    "    def _rescale(self , low_res,high_res):\n",
    "        high_res = high_res * 2.0-1.0\n",
    "        return low_res , high_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(self, batch_size, threads=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(self.image_paths)\n",
    "    dataset = dataset.map(self._parse_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(self._random_crop,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(self._high_low_res_pairs,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(self._rescale,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(30).batch(batch_size,drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model architechure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSRGAN(object):\n",
    "    def _init_(self, args):\n",
    "        self.hr_height=args.hr_size\n",
    "        self.hr_width=args.hr_size\n",
    "        self.lr_height=self.hr_height//4\n",
    "        self.lr_width=self.hr_width//4\n",
    "        self.lr_shape = (self.lr_height,self.lr_width, 3 )\n",
    "        self.hr_shape = (self.hr_height,self.hr_width, 3 )\n",
    "        self.iterations = 0\n",
    "        \n",
    "        self.n_residual_blocks=6\n",
    "        \n",
    "        self.gen_schedule = keras.optimizers.schedules.ExponentialDecay(args.lr, decay_steps=100000, decay_rate=0.1, staircase= True)\n",
    "        \n",
    "        self.disc_schedule = keras.optimizers.schedules.ExponentialDecay(args.lr*s, decay_steps=100000, decay_rate=0.1, staircase= True)\n",
    "        \n",
    "        self.gen_optimizer = keras.optimizers.Adam(learning_rate=self.gen_schedule)\n",
    "        self.disc_optimizer = keras.optimizers.Adam(learning_rate=self.disc_schedule)\n",
    "        \n",
    "        self.vgg = self.build_vgg()\n",
    "        self.vgg.trainable = False\n",
    "        \n",
    "        patch = int(self.hr_height/2**4)\n",
    "        self.disc_patch = (patch,patch,1)\n",
    "        \n",
    "        self.gf = 32\n",
    "        self.df = 32\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.generator = self.build_generator()\n",
    "        \n",
    "    @tf.function\n",
    "    def content_loss(self, hr , sr):\n",
    "        sr = keras.application.vgg19.preprocess_input(((sr+1.0)*255)/2.0)\n",
    "        hr = keras.application.vgg19.preprocess_input(((hr+1.0)*255)/2.0)\n",
    "        sr_features = self.vgg(sr)/12.75\n",
    "        hr_features = self.vgg(hr)/12.75\n",
    "        return tf.keras.losses.MeanSquaredError()(hr_features, sr_features)\n",
    "#using a pretrained model vgg19 which is trained for many images\n",
    "\n",
    "    def build_vgg(self):\n",
    "        vgg=keras.application.VGG19(weights='imagenet',input_shape=self.hr_shape,include_top=False)\n",
    "        vgg.trainable= False\n",
    "        \n",
    "        for layer in vegg.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        mode= keras.models.Model(input=vgg.input, outputs=vgg.get_layer(\"block5_conv4\").output)\n",
    "        \n",
    "        return model\n",
    "    def build_generator(self):\n",
    "        def _make_divisible(v, divisor, min_value=None):\n",
    "            if min_value is None:\n",
    "                min_value = divisor\n",
    "                \n",
    "            new_v = max(min_value, int(v+divisor/2) // divisor * divisor)\n",
    "            \n",
    "            if new_v <0.9*v:\n",
    "                new_v +=divisor\n",
    "            return new_v\n",
    "        def residual_block(inputs, filters, block_id, expansion=6, stride=1, alpha=1.0):\n",
    "            channel_axis = 1 if keras.backed.image_data_format()=='channel_frist' else -1\n",
    "            in_channels = keras.backend.int_shape(inputs)[channel_axis]\n",
    "            \n",
    "            pointwise_conv_filters = int(filters * alpha)\n",
    "            pointwise_filters= _make_divisible(pointwise_conv_filters, 8)\n",
    "            x = inputs\n",
    "            prefix = 'block_{}_' .format(block_id)\n",
    "            \n",
    "            if block_id:\n",
    "                x = keras.layers.conv2D(expansion * in_channels, kernel_size = 1, padding='same',use_bias= True,activation=None, name=prefix +'expand')(x)\n",
    "                x = keras.layers.BatchNormalization(axis=channel_axis, epsilon=1e-3,padding='same',use_bias=True , activation=None,name=prefix+'expand')(x)\n",
    "                x = keras.layers.Activation('relu', name=prefix+'expand_relu')(x)\n",
    "            else:\n",
    "                prefix = 'expanded_conv_'\n",
    "            x=keras.layers.DepthwiseConv2D(kernel_size=3,\n",
    "                                          strides=stride,\n",
    "                                          activation=None,\n",
    "                                          use_bias=True,\n",
    "                                          padding='same' if stride == 1 else 'valid',\n",
    "                                          name= prefix+'depthwise')(x)\n",
    "            \n",
    "            x= keras.layers.BatchNormalization(axis=channel_axis,\n",
    "                                              epsilon=1e-3,\n",
    "                                              momentum=0.999,\n",
    "                                              name=prefix+'depthwise_BN')(x)\n",
    "            \n",
    "            x= keras.layers.Activation('relu', name=prefix+'depthwise_relu')(x)\n",
    "            \n",
    "            x=keras.layers.conv2D(pointwise_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 padding='same',\n",
    "                                 activation=None,\n",
    "                                 use_bias=True,\n",
    "                                 name=prefix+'project')(x)\n",
    "            \n",
    "            x= keras.layers.BatchNormalization(axis=channel_axis,\n",
    "                                              epsilon=1e-3,\n",
    "                                              momentum=0.999,\n",
    "                                              name=prefix+'project_BN')(x)\n",
    "            if in_channel == poinwise_filters and stride == 1:\n",
    "                return keras.layers.Add(name=prefix + 'add')([inputs,x])\n",
    "            return x\n",
    "        def deconv2D(layer_input, filters):\n",
    "            \n",
    "            u = keras.layers.conv2D(filters, kernel_size=3,strides=1, padding='same')(layer_input)\n",
    "            u = tf.nn.depth_to_space(u,2)\n",
    "            u = keras.layers.PReLU(shared_axes=[1,2])(u)\n",
    "            return u\n",
    "        img_lr = keras.Input(shape=self.lr_shape)\n",
    "        \n",
    "        c1=keras,layers.conv2D(self.gf,kernel_size=3,strides=1,padding='same')(img_lr)\n",
    "        \n",
    "        c1=keras,layers.BatchNormalization()(c1)\n",
    "        \n",
    "        c1=keras,layers.PReLU(shared_axes=[1,2])(c1)\n",
    "        \n",
    "        r=residual_block(c1,self.gf,0)\n",
    "        for idx in range(1,self.n_residual_blocks):\n",
    "            r=residual_block(r,self.gf,idx)\n",
    "            \n",
    "        c2=keras,layers.conv2D(self.gf,kernel_size=3,strides=1,padding='same')(r)\n",
    "        c2=keras,layers.BatchNormalization()(c2)\n",
    "        c2=keras,layers.Add([c2,c1])\n",
    "        \n",
    "        u1 = decon2d(c2, self.gf*4)\n",
    "        u2 = decon2d(u1, self.gf*4)\n",
    "        \n",
    "        gen_hr = keras.layers.conv2D(3,kernel_size=3,strides=1,padding='same',activation='tanh')(u2)\n",
    "        \n",
    "        return keras.models.Model(img_lr,gen_hr)\n",
    "    def build_discriminator(self):\n",
    "        def d_block(layer_input, filters, strides=1, bn=True):\n",
    "            \n",
    "            d=keras.layers. Conv2D(filters, kernel_size=3, strides = strides, padding='same')(layer_input)\n",
    "            if bn:\n",
    "                d=keras.layersBatchNormalization (momentum-0.8)(d)\n",
    "            d= keras.layersLeakyReLU (alpha=0.2) (d)\n",
    "            return d\n",
    "                                \n",
    "        d0= keras.layers.input (shape=self.hr_shape)\n",
    "        \n",
    "        d1 = d_block(d0, self.df, bn=False)\n",
    "        d2 = d_block(d1, self.df, strides=2)\n",
    "        d3 = d_block(d2, self.df)\n",
    "        d4 = d_block(d3, self.df, strides=2)\n",
    "        d5 = d_block(d4, self.df*2)\n",
    "        d6 = d_block(d5, self.df*2, strides-2)\n",
    "        d7 = d_block(d6, self.df*2) \n",
    "        d8 = d_block(d7, self.df*2, strides=2)\n",
    "        \n",
    "        validity=keras.layers.Conv2D(1, kernel_size=1, strides =1, activation='sigmoid', padding='same') (d8)\n",
    "        return keras.model.Model(d0,validity)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument ('--image_dir', type=str, help='Path to high resolution image directory.')\n",
    "parser.add_argument ('--batch_size', default=8, type=int, help='Batch size for training.')\n",
    "parser.add_argument('--epochs', default=1, type=int, help='Number of epochs for training')\n",
    "parser.add_argument ('--hr_size', default=384, type=int, help='Low resolution input size.') \n",
    "parser.add_argument ('--lr', default=1e-4, type=float, help=\"Learning rate for optimizers.\") \n",
    "parser.add_argument('--save_iter', default=200, type=int, help='The number of iterations to save the tensorboard summaries and models.')\n",
    "\n",
    "@tf.function\n",
    "def pretrain_step(model, x, y):\n",
    "    \"\"\"\n",
    "    Single step of generator pre-training. \n",
    "    Args:\n",
    "        model: A model object with a tf keras compiled generator.\n",
    "        x: The low resolution image tensor.\n",
    "        y: The high resolution image tensor.\n",
    "        \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_hr = model.generator(x)\n",
    "        loss_mse= tf.keras.losses.MeanSquaredError()(y, fake_hr)\n",
    "    \n",
    "    grads = tape.gradient(loss_mse, model.generator.trainable_variables)\n",
    "    model.gen_optimizer.apply_gradients(zip(grads, model.generator.trainable_variables))\n",
    "    \n",
    "    return loss_mse\n",
    "\n",
    "def pretrain_generator(model, dataset, writer):\n",
    "    \"\"\"Function that pretrains the generator slightly, to avoid local minima.\n",
    "    Args:\n",
    "        model: The keras model to train.\n",
    "        dataset: A tf dataset object of low and high res images to pretrain over.\n",
    "        writer: A summary writer object.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with writer.as_default():\n",
    "        iteration = 0\n",
    "        for _ in range(1):\n",
    "            for x,y in dataset:\n",
    "                loss = pretrain_step(model,x,y)\n",
    "                if iteration % 20 ==0:\n",
    "                    tf.summary.scalar('MSE Loss', loss,step=tf.cast(iteration,tf.int64))\n",
    "                    writer.flush()\n",
    "                iteration += 1\n",
    "                \n",
    "@tf.function\n",
    "def train_step(model, x,y):\n",
    "    \"\"\"Single train step function for the SRGAN.\n",
    "    Args:\n",
    "        model: An object that contains a tf keras compiled discriminator model.\n",
    "        x: The low resolution input image.\n",
    "        y: The desired high resolution output image.\n",
    "    Returns:\n",
    "        d_loss: The mean loss of the discriminator.\n",
    "    \"\"\" \n",
    "\n",
    "# Label smoothing for better gradient flow\n",
    "\n",
    "    valid = tf.ones((x.shape[0],) + model.disc_patch)\n",
    "\n",
    "    fake = tf.zeros((x.shape[0],)+ model.disc_patch)\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        # From Low res. image generate high res. version\n",
    "        fake_hr = model.generator(x)\n",
    "\n",
    "        # Train the discriminators (original images = real / generated Fake)\n",
    "\n",
    "        valid_prediction = model.discriminator (y)\n",
    "        fake_prediction = model.discriminator(fake_hr)\n",
    "        #Generator Loss\n",
    "        content_loss = model.content_loss (y, fake_hr)\n",
    "        adv_loss = le-3* tf.keras.losses.BinaryCrossentropy() (valid, fake_prediction)\n",
    "        mse_loss = tf.keras.losses.MeanSquaredError() (y, fake_hr)\n",
    "        perceptual_loss = content_loss + adv_loss + mse_loss\n",
    "        \n",
    "        # Discriminator Loss\n",
    "        valid_loss = tf.keras.losses.BinaryCrossentropy()( valid, valid_prediction)\n",
    "        fake_loss = tf.keras.losses.BinaryCrossentropy() (fake, fake_prediction)\n",
    "        d_loss = tf.add(valid_loss, fake_loss)\n",
    "        \n",
    "    # Backprop on Generator\n",
    "    gen_grads = gen_tape.gradient (perceptual_loss, model.generator.trainable_variables)\n",
    "    model.gen_optimizer.apply_gradients(zip(gen_grads, model.generator.trainable_variables))\n",
    "\n",
    "    # Backprop on Discriminator\n",
    "    disc_grads = disc_tape.gradient(d_loss, model.discriminator.trainable_variables)\n",
    "    model.disc_optimizer.apply_gradients(zip (disc_grads, model.discriminator.trainable_variables))\n",
    "\n",
    "    return d_loss, adv_loss, content_loss, mse_loss\n",
    "\n",
    "def train(modeldatasetlog_iter, writer):\n",
    "    \"\"\"Function that defines a single training step for the SR-GAN\n",
    "    Args:\n",
    "        model: An object that contains tf keras compiled generator and discriminator models.\n",
    "            dataset: A tf data object that contains low and high res images\n",
    "                log_iter: Number of iterations after which to add logs in tensorboard.\n",
    "                    writer: Summary writer\n",
    "                    \"\"\"\n",
    "    with writer.as_default():\n",
    "\n",
    "    # Iterate over dataset\n",
    "\n",
    "        for x, y in dataset:\n",
    "            disc_oss, adv_loss, content_loss, mse_loss=rain_step (model, x, y)\n",
    "            # Log tensorboard summaries if Log iteration is reached. -8\n",
    "            if model.iterations %log_iter ==0:\n",
    "                tf.summary.scalar('Adversarial Loss',adv_loss, step=model.iterations)\n",
    "                tf.summary.scalar('Content Loss',content_loss, step=model.iterations)\n",
    "                tf.summary.scalar('MSE Loss',mse_loss, step-model.iterations)\n",
    "                tf.summary.scalar('Discriminator Loss',disc_loss, step-model.iterations)\n",
    "                tf.summary.image('Low Res',tf.cast(255*x, tf.uint8), step=model.iterations)\n",
    "                tf.summary.image('High Res',tf.cast(255*(y+ 1.0)/2.0, tf.uint8), step=model.iterations)\n",
    "                tf.summary.image('Generated', tf.cast (255*(model.generator.predict(x)+ 1.0)/2.0, tf.uint8),step-model.iterations)\n",
    "                model.generator.save('models/generator.h5')\n",
    "                model.discriminator.save('models/discriminator.h5')\n",
    "                writer.flush()\n",
    "            model.iterations +=1\n",
    "def main():\n",
    "    #parse the cli arguments.\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    #create directory for saving trained models.\n",
    "    if not os.path.exists('models'):\n",
    "        os.makedirs('models')\n",
    "    #Create the tensorflow dataset.\n",
    "    ds = DataLoader(args.image_dir, args.hr_size).dataset (args.batch_size)\n",
    "    #Initialize the GAN object. \n",
    "    gan = FastSRGAN(args)\n",
    "\n",
    "    #Define the directory for saving pretrainig loss tensorboard summary.\n",
    "    pretrain_summary_writer = tf.summary.create_file_writer('logs/pretrain')\n",
    "\n",
    "    # Run pre-training\n",
    "\n",
    "    pretrain_generator(gan, ds, pretrain_summary_writer)\n",
    "\n",
    "    #Define the directory for saving the SRGAN training tensorbaord summary.\n",
    "    train_summary_writer = tf.summary.create_file_writer('logs/train')\n",
    "\n",
    "    #Run training.\n",
    "\n",
    "    for _ in range(args.epochs):\n",
    "\n",
    "        train(gan, ds, args.save_iter, train_summary_writer)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_dir IMAGE_DIR] [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--hr_size HR_SIZE] [--lr LR] [--save_iter SAVE_ITER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Jaisriram\\AppData\\Roaming\\jupyter\\runtime\\kernel-f098f9a3-b99e-4455-8c1b-63d9f30f7f1f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaisriram\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
